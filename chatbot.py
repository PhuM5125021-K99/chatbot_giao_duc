# chatbot.py ‚Äî phi√™n b·∫£n d√πng similarity_search (kh√¥ng c·∫ßn RetrievalQA import)
import os
from langchain_community.llms import Ollama
from langchain_core.prompts import PromptTemplate
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import Chroma
from langchain_ollama import OllamaEmbeddings


# ====== C·∫•u h√¨nh ======
DATA_PATH = "kien_thuc_giao_duc.txt"  # ƒë∆∞·ªùng d·∫´n file d·ªØ li·ªáu vƒÉn b·∫£n
CHROMA_DIR = "data/chroma_db"
OLLAMA_BASE = "http://localhost:11434"
EMBED_MODEL = "nomic-embed-text"   # n·∫øu Ollama c·ªßa b·∫°n c√≥ model embedding kh√°c, ƒë·ªïi cho ph√π h·ª£p
LLM_MODEL = "gemma2:9b"

# ====== 1) Load d·ªØ li·ªáu ======
if not os.path.exists(DATA_PATH):
    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu: {DATA_PATH}")

print("üìò ƒêang t·∫£i d·ªØ li·ªáu...")
loader = TextLoader(DATA_PATH, encoding="utf-8")
documents = loader.load()

# ====== 2) Chia nh·ªè vƒÉn b·∫£n ======
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
chunks = splitter.split_documents(documents)
print(f"‚úÖ ƒê√£ chia th√†nh {len(chunks)} ƒëo·∫°n.")

# ====== 3) T·∫°o embeddings + Chroma vectorstore (n·∫øu ch∆∞a c√≥) ======
# N·∫øu b·∫°n mu·ªën t√°i s·ª≠ d·ª•ng DB ƒë√£ t·ªìn t·∫°i (ƒë·ªÉ kh√¥ng ph·∫£i t·∫°o l·∫°i m·ªói l·∫ßn),
# c√≥ th·ªÉ ki·ªÉm tra CHROMA_DIR t·ªìn t·∫°i r·ªìi load thay v√¨ rebuild.
print("üî¢ T·∫°o embeddings v√† l∆∞u v√†o Chroma...")
embeddings = OllamaEmbeddings(model=EMBED_MODEL, base_url=OLLAMA_BASE)

# T·∫°o/ghi Chroma DB
vectorstore = Chroma.from_documents(chunks, embedding=embeddings, persist_directory=CHROMA_DIR)
vectorstore.persist()
print("üíæ Vectorstore ƒë√£ s·∫µn s√†ng.")

# ====== 4) Kh·ªüi t·∫°o LLM (Ollama) ======
llm = Ollama(model=LLM_MODEL, base_url=OLLAMA_BASE)

# ====== 5) Prompt template ======
EDU_PROMPT = (
    "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ gi√°o d·ª•c, th√¢n thi·ªán v√† tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát. "
    "D·ª±a tr√™n ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p, h√£y tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch r√µ r√†ng v√† chi ti·∫øt. "
    "N·∫øu th√¥ng tin kh√¥ng c√≥ trong ng·ªØ c·∫£nh, h√£y n√≥i 'T√¥i ch∆∞a c√≥ d·ªØ li·ªáu v·ªÅ n·ªôi dung n√†y.'"
)
prompt = PromptTemplate(
    input_variables=["context", "question"],
    template=EDU_PROMPT + "\n\nNg·ªØ c·∫£nh:\n{context}\n\nC√¢u h·ªèi: {question}\nTr·∫£ l·ªùi:"
)

# ====== 6) V√≤ng l·∫∑p h·ªèi ƒë√°p: t√¨m ƒëo·∫°n li√™n quan + sinh c√¢u tr·∫£ l·ªùi ======
print("\nüéì Chatbot gi√°o d·ª•c s·∫µn s√†ng! (g√µ 'exit' ƒë·ªÉ tho√°t)\n")

while True:
    q = input("üë©‚Äçüéì B·∫°n: ").strip()
    if q.lower() == "exit":
        print("üëã T·∫°m bi·ªát! Ch√∫c b·∫°n h·ªçc t·ªët.")
        break

    try:
        # 6.1 T√¨m top-k ƒëo·∫°n li√™n quan (similarity search)
        top_k = 3
        results = vectorstore.similarity_search(q, k=top_k)  # tr·∫£ v·ªÅ list Document
        context = "\n\n".join([doc.page_content for doc in results]) if results else ""

        if not context:
            # N·∫øu kh√¥ng t√¨m th·∫•y ƒëo·∫°n n√†o, cho th√¥ng b√°o ng·∫Øn r·ªìi v·∫´n g·ªçi LLM (ho·∫∑c b·ªè qua)
            print("ü§ñ Tr·ª£ l√Ω: T√¥i ch∆∞a c√≥ d·ªØ li·ªáu v·ªÅ n·ªôi dung n√†y.\n")
            continue

        # 6.2 Gh√©p prompt v·ªõi context
        final_prompt = prompt.format(context=context, question=q)

        # 6.3 G·ªçi LLM ƒë·ªÉ sinh c√¢u tr·∫£ l·ªùi
        answer = llm.invoke(final_prompt)

        print(f"ü§ñ Tr·ª£ l√Ω: {answer}\n")

    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {e}\n")
